I"–<p>These are all classical models of forecasting based on time series
data, with slight differences. This post focuses on the conceptual
differences to gain an intuition and overview.</p>

<h2 id="autoregressive-model">Autoregressive model</h2>

<p><em>Autoregression</em> refers to a regression model based on itself
(‚Äúauto‚Äù). Basically, it takes <em>p</em> number of time steps before the one
to be forecast and fits a regression model based on that. Or, in other
words, predict the current value based on <em>p</em> previous values. Time
steps before the one to be forecast are referred to as <em>lags</em>, so one
could also say, predict the current value based on <em>p</em> lags. And the
number of <em>lags</em> is called the <em>order</em> of the model.</p>

<p>[X_{t}=c+\sum <em>{i=1}^{p}\varphi _{i}X</em>{t-i}+\varepsilon _{t}\,]</p>

<ul>
  <li>$X_{t}$: value to be forecast at time $t$.</li>
  <li>$c$: some constant value</li>
  <li>$\varepsilon_{t}$: error value at time $t$</li>
  <li>$p$ number of <em>lags</em>, or <em>order</em> of the model</li>
  <li>$\varphi_{i}$: model parameter at index $i$</li>
</ul>

<h2 id="moving-average-regression-model">Moving-average regression model</h2>

<p>The <em>moving-average regression model</em> takes a slightly different
approach. It takes the average of the time series, and then predicts
the current value based on the error term of <em>n</em> previous time
steps. Similar to above, the <em>n</em> is referred to as the <em>order</em>.</p>

<p>How does this compare to the autoregressive approach above?</p>

<p>Pros:</p>

<ul>
  <li>The error terms of the lags are modeled to affect the forecasted
value directly, rather than indirectly.</li>
  <li>The error influence from lags is limited to the <em>order</em>, and not
infinitely like the autoregressive approach.</li>
</ul>

<p>Cons:</p>

<ul>
  <li>Fitting the model can be more complicated, as the error terms are
not directly observable (they are included within the lag total
values).</li>
</ul>

<p>[X_{t}=\mu +\varepsilon _{t}+\theta _{1}\varepsilon _{t-1}+\cdots +\theta _{q}\varepsilon _{t-q}\,]</p>

<ul>
  <li>$X_{t}$: value to be forecast at time $t$.</li>
  <li>$\mu$: the average of the series</li>
  <li>$\varepsilon_{t}$: error value at time $t$</li>
  <li>$q$: the number of <em>lags</em> to use, or <em>order</em> of the model</li>
  <li>$\theta_{t}$: the parameter of the model at time <em>t</em></li>
</ul>

<p>This is alternatively written with the summmation operator like so:</p>

<p>[X_{t}=\mu +\varepsilon _{t}+\sum _{i=1}^{q}\theta _{i}\varepsilon _{t-i}.\,]</p>

<p>Note that this model name sounds similar to the <em>moving average</em>
concept from statistics, but is conceptually different.</p>

<h2 id="autoregressive-moving-average-model-arma">Autoregressive moving average model (ARMA)</h2>

<p>After reviewing the above, <em>ARMA</em> becomes much easier to understand,
as it‚Äôs simply a combination of the above two.</p>

<p>[X_{t}=c+\varepsilon <em>{t}+\sum _{i=1}^{p}\varphi _{i}X</em>{t-i}+\sum _{i=1}^{q}\theta _{i}\varepsilon _{t-i}.\,]</p>

<p><em>ARMA</em> forecasts the targeted value as a combination of both <em>p</em>
previous lag values and <em>q</em> previous error values.</p>

<h2 id="autoregressive-integrated-moving-average-arima">Autoregressive integrated moving average (ARIMA)</h2>

<p>The <em>ARIMA</em> approach extends <em>ARMA</em> by using <em>difference</em> values as
opposed to the lag values themselves. This is the <em>integrated</em> part.</p>

<p>What is a <em>difference</em> value? A <em>difference</em> value for time step <em>t</em>
would be the differnce between it and the previous value at time step
<em>t-1</em>. Or, formulaically:</p>

<p>[X_{t} - X_{t-1}]</p>

<p>Using the differences as opposed to the values themselves is an effort
to
eliminate
<a href="https://en.wikipedia.org/wiki/Stationary_process"><em>non-stationarity</em></a>,
or differences in the data when shifted in time. Difference values may
be calculated repeatedly on a series, also giving them an <em>order</em>.</p>

<p>The following links from MIT OCW Math give a broad overview of Time Series Analysis.</p>

<p><a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/video-lectures/lecture-8-time-series-analysis-i/">Time Series Analysis Lecture 1</a></p>

<p><a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/video-lectures/lecture-11-time-series-analysis-ii/">Time Series Analysis Lecture 2</a></p>

<p><a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/video-lectures/lecture-12-time-series-analysis-iii/">Time Series Analysis Lecture 3</a></p>

:ET